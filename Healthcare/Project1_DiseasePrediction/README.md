# Project 1 - Disease Prediction (Diabetes Dataset)

## ğŸ“Œ Problem Statement
Predict the likelihood of diabetes in patients based on clinical features.  
This project demonstrates endâ€‘toâ€‘end data cleaning, imputation, and modeling using the **Pima Indians Diabetes Dataset** (768 records).

## ğŸ“Š Dataset
- **Source**: Kaggle â€“ Diabetes Dataset by Mehmet Akturk (mathchi)  
- **Size**: 768 rows Ã— 9 columns  
- **Features**:
  - Pregnancies
  - Glucose
  - BloodPressure
  - SkinThickness
  - Insulin
  - BMI
  - DiabetesPedigreeFunction
  - Age
  - Outcome (target: 0 = nonâ€‘diabetic, 1 = diabetic)

## ğŸ›  Tools & Workflow
- **Alteryx Designer**: Data cleaning, imputation, workflow automation
- **Python (Pandas, Scikitâ€‘Learn)**: Modeling and evaluation
- **Power BI**: Dashboard visualization
- **Git & GitHub**: Version control and portfolio publishing

## ğŸ”„ Process Steps (Alteryx)
1. **Input Data** â€“ Load raw CSV (768 records).
2. **Browse** â€“ Inspect dataset, identify hidden missing values (zeros).
3. **Summarize** â€“ Compute median values for Glucose, BloodPressure, SkinThickness, Insulin, BMI.
4. **Formula + Join** â€“ Add JoinKey, merge medians into dataset.
5. **Formula** â€“ Replace 0â€™s with median values.
6. **Select** â€“ Clean schema, drop helper fields.
7. **Browse** â€“ Verify cleaned dataset.
8. **Output Data** â€“ Export `data_diabetes_clean.csv`.
9. **Modeling** â€“ Train baseline classifiers (Logistic Regression, Random Forest).
10. **Dashboard** â€“ Visualize patient risk distribution in Power BI.

## âœ… Results
- Cleaned dataset with no biologically impossible values (e.g., BMI = 0).
- Baseline model accuracy ~75â€“80% (to be refined).
- Dashboard showing risk factors and prediction outcomes.

## ğŸ§© Workflow Diagram
![Diabetes Cleaning Workflow](../images/diabetes_cleaning_workflow.png)

The workflow includes Input, Browse, Summarize, Formula, Join, Select, and Output tools.

## ğŸ“Š Modeling and Evaluation (Python)
- Logistic Regression baseline accuracy: ~75â€“80%
- Random Forest baseline accuracy: ~78â€“82%
- Evaluation metrics included Precision, Recall, F1-score, and ROC curve

## Sections:
Data Import: Load data_diabetes_clean.csv
Exploratory Analysis: Quick stats, distributions
Train/Test Split: 70/30 or 80/20
Baseline Models: Logistic Regression, Random Forest
Evaluation Metrics: Accuracy, Precision, Recall, F1, ROC Curve

# Diabetes Prediction: Logistic Regression vs Random Forest

## ğŸ“Œ Project Overview
This project applies machine learning to predict diabetes using patient health metrics.  
Two models were compared:
- **Logistic Regression** â†’ interpretable, transparent coefficients.
- **Random Forest** â†’ robust, nonlinear, higher recall and accuracy.

The notebook demonstrates end-to-end workflow: preprocessing, modeling, evaluation, ROC curves, and calibration curves.

---

## âš™ï¸ Workflow
1. **Data Preprocessing**
   - Class balance check
   - Scaling for Logistic Regression
   - Exploratory analysis (histograms, correlations)

2. **Modeling**
   - Logistic Regression baseline + threshold tuning
   - Random Forest with class balancing + feature importance

3. **Evaluation**
   - Confusion matrices
   - Classification reports
   - ROC curve comparison (AUC)
   - Calibration curves (probability reliability)

4. **Comparison**
   - Side-by-side metrics table
   - Grouped bar charts for precision, recall, F1, accuracy

---

## ğŸ“Š Key Results
- Logistic Regression: Accuracy **0.71**, Diabetic Recall **0.50**, better calibration.
- Random Forest: Accuracy **0.75**, Diabetic Recall **0.78**, stronger discrimination (AUC ~0.80).
- ROC curves show Random Forest separates classes better.
- Calibration curves show Logistic Regression provides more reliable probabilities.

---

## ğŸ¯ Recruiter Narrative
This project demonstrates:
- Ability to balance **interpretability vs robustness**.
- Use of **threshold tuning** to prioritize healthcare-specific metrics.
- Advanced evaluation with **ROC and calibration curves**.
- Clear communication of trade-offs for recruiter and stakeholder audiences.

---

## ğŸ“‚ Repository Structure
- `notebooks/diabetes_prediction.ipynb` â†’ Full modeling workflow.
- `data/` â†’ Dataset.
- `README.md` â†’ Project summary (this file).

---

## ğŸš€ Next Steps (Not included in this project)
- Add ROC and PR curves for deeper evaluation.
- Explore calibration methods (Platt scaling, isotonic regression).
- Extend to other models (XGBoost, SVM) for comparison.

---

data-analytics-portfolio/
â”‚â”€â”€ README.md                        # Portfolio overview (root)
â”‚â”€â”€ Healthcare/
â”‚   â””â”€â”€ Project1_DiseasePrediction/
â”‚       â”œâ”€â”€ README.md                # Project-specific documentation
â”‚       â”œâ”€â”€ data/
â”‚       â”œâ”€â”€ workflows/
â”‚       â”œâ”€â”€ notebooks/
â”‚       â””â”€â”€ dashboard/
â”‚       â””â”€â”€ images/

data-analytics-portfolio/Healthcare/diabetes-prediction/
â”‚
â”œâ”€â”€ README.md                  # Root-level project summary
â”œâ”€â”€ requirements.txt            # Dependencies
â”œâ”€â”€ .gitignore                  # Ignore checkpoints, envs, etc.
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ diabetes_prediction.ipynb   # Full modeling workflow
â”‚
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ Alteryx_Workflow_Images/    # Organized Alteryx workflow screenshots
â”‚   â”‚   â”œâ”€â”€ workflow1.png
â”‚   â”‚   â”œâ”€â”€ workflow2.png
â”‚   â”‚   â””â”€â”€ workflow3.png
â”‚   â”‚
â”‚   â””â”€â”€ Python_Images/              # Visuals from Python (plots, charts)
â”‚       â”œâ”€â”€ roc_curve.png
â”‚       â”œâ”€â”€ calibration_curve.png
â”‚       â””â”€â”€ comparison_chart.png
